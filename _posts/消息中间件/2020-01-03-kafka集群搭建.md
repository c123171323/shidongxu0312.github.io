---
layout: post
title:  kafka集群搭建
categories: 消息中间件
description: kafka集群搭建
keywords: 消息中间件
---
前提需要JDK

1.安装Zookeeper

选用当前次新安装包 3.4.13，当前最新kafka2.20（ scala 2.12），新机器需要自行安装jdk

为了快速学习，按照Kafka非常难学这本书上的演示路径

创建（Zookeeper集群从44到46ID由1到3，Kafka集群从44到46由0到2）

实际生产环境不会有煞笔使用Standalone的Zookeeper的，这里只列出集群方式（可配置Zookeeper分布式启动命令，这里国网云机器就不去配置免密连接了，手动麻烦点启动），自行测试可以安装单节点的standalone模式，这个在深入理解kafka的书里面可以找到

| 解压切换到配置文件夹                                         | cd conf（zookeeper）                                         |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| 修改zoo_sample配置文件                                       | cp zoo_sample.cfg zoo.cfg   vi zoo.cfg                       |
| 具体配置修改内容                                             | dataDir=/data/soft/new/zkdata   clientPort=2181   server.1=192.100.2.44:2888:3888   server.2=192.100.2.45:2888:3888   server.3=192.100.2.46:2888:3888 |
| 在另外两个节点上执行同样的步骤                               | 1.创建文件目录   mkdir -p /data/soft/new   2.创建数据存放目录   mkdir /data/soft/new/zkdata   3.数据存放目录中创建一个文件   vi /data/soft/new/zkdata/myid   写入对应的整数id   举例 server.1=192.100.2.44:2888:3888   id为1   4.从已解压配置完成的节点上将zookeeper跨节点传入   scp -r zookeeper root   @192.100.2.45:/data/soft/new   scp -r zookeeper root   @192.100.2.46:/data/soft/new |
| 配置环境变量（三节点）                                       | vi ~/.bash_profile   #添加如下内容   export   ZK_HOME=/data/soft/new/zookeeper   export   PATH=$PATH:$ZK_HOME/bin       source ~/.bash_profile |
| 启动Zookeeper                                                | zkServer.sh start（启动三台）                                |
| 查看启动状态                                                 | jps或者zkServer.sh   status（注意防火墙的因素，如果连接不上查出的状态会提示可能没有启动） |
| 安装Kafka                                                    | 直接解压，配置环境变量（注意，如果下载的是源代码需要自行编译）   vi ~/.bash_profile   export   KAFKA_HOME=/data/soft/new/kafka   export   PATH=$PATH:$KAFKA_HOME/bin   source ~/.bash_profile |
| 配置Kafka                                                    | vi   /data/soft/new/kafka/config/server.properties   #修改内容   #设置Kafka节点唯一ID   broker.id=0   #开启删除Kafka主题属性   delete.topic.enable=true   #非SASL模式配置Kafka集群   listeners=PLAINTEXT://192.100.3.51:9092   #设置网络请求线程数   num.network.threads=10   #设置磁盘IO请求线程数   num.io.threads=20   #设置发送buffer字节数   socket.send.buffer.bytes=1024000   #设置收到buffer字节数   socket.receive.buffer.bytes=1024000   #设置最大请求字节数   socket.request.max.bytes=1048576000   #设置主题分区   num.partitions=6   #设置消息记录存储路径   log.dirs=/data/soft/new/kafka/data   #设置主题保留时间   log.retention.hours=168   #设置Zookeeper的连接地址   zookeeper.connect=192.100.3.51:2181,192.100.3.52:2181,192.100.3.53:2181   #设置Zookeeper连接超时时间   zookeeper.connection.timeout.ms=60000 |
| 配置好一台主机上的Kafka系统后，使用跨节点传输，同步安装包    | scp -r kafka root   @192.100.2.45:/data/soft/new   scp -r kafka root   @192.100.2.46:/data/soft/new   由于Kafka集群中每个代理Broker节点的ID必须唯一，所以同步完成后需要将另两台主机上的broker.id属性值改为其他不重复的正整数 |
| 启动kafka                                                    | kafka-server-start.sh   $KAFKA_HOME/config/server.properties &   测试时后台启动可以   kafka-server-start.sh   $KAFKA_HOME/config/server.properties 1>/dev/null 2>&1   &   发现一个问题，即使我后台启动，我关了xshell也会掉，   需要使用守护进程模式启动，可以解决问题   kafka-server-start.sh -daemon $KAFKA_HOME/config/server.properties   1>/dev/null 2>&1 & |
| 验证                                                         | Kafka-topics.sh   --list -zookeeper 地址1:2181  地址2:2181   地址3:2181       同时可以显示Kafka内部主题 _   _consumer_offsets 主要用来记录Kafka消费者（Consumer）产生的消费记录，其中包含偏移量（Offset）、时间戳（Timestamp）和线程名等信息。这个不要乱动 |
| 安装和配置Kafka监控工具                                      | Kafka-eagle（可以直接下载编译过的版本）                      |
| 如果是未编译版本，需要先安装maven，和java安装过程类似，就不多说了 | export   MAVEN_HOME=/usr/local/maven   export   PATH=$PATH:$MAVEN_HOME/bin   离线环境 maven连不到仓库，下载不了插件，导致失败。。。（按理说服务器可以配置yum代理连网，但是国网云机器不要这么操作）   尝试windows下使用idea打包（主要原因是ke包需要插件，离线无法下，离线安装过于麻烦，用idea吧）   找到了一个编译好的包，如何编译tar.gz成为待解决问题，最新版的bin包好像不是很好使，用了1.20版本的包轻松搞定！1.20版本的包在linux版本下完美运行，window版本界面无法显示       <http://www.cnblogs.com/smartloli/p/9371904.html> |
| 编辑环境变量                                                 | vi ~/.bash_profile   export   KE_HOME=/data/soft/new/kafka-eagle   export   PATH=$PATH:$KE_HOME/bin   source ~/.bash_profile |
| 配置kafka eagle系统文件                                      | System-config.properties配置文件       #设置Kafka多集群的Zookeeper地址   Kafka.eagle.zk.cluster.alias=cluster1   Cluster1.zk.list=192.100.2.44:2181,192.100.2.45:2181,192.100.2.46:2181   #   Cluster2.zk.list=192.100.2.44:2181,192.100.2.45:2181,192.100.2.46:2181   #配置Zookeeper连接池大小   Kafka.zk.limit.size=25       #浏览器访问Kafka Eagle的端口地址   Kafka.eagle.webui.port:8048       #kafka的消费信息是否存储到topic中   Kafka.eagle.offset.storage=kafka       #配置邮件告警服务器   Kafka.eagle.mail.enable=false   Kafka.eagle.mail.sa=alert_sa   Kafka.eagle.mail.username=alert_sa@126.com   Kafka.eagle.mail.password=123456   Kafka.eagle.mail.server.host=smtp.126.com   Kafka.eagle.mail.server.port=25       #管理员删除topic的口令   Kafka.egale.topic.token=keadmin       #是否开启kafka sasl安全认证   Kafka.egale.sasl.enable=false   Kafka.eagle.sasl.protocol=SASL_PLAINTEXT   Kafka.eagle.sasl.mechanism=PLAIN   Kafka.eagle.sasl.client=/data/soft/new/kafka-eagle/conf/kafka_client_jaas.conf       #kafka eagle 数据存储到MySQL（这个按自己的需要配置）   #Kafka.eagle.driver=com.mysql.jdbc.Driver   #kafka.eagle.url=jdbc:mysql://127.0.0.1:3306/ke?useUnicode=ture&characterEncoding=UTF-8&zeroDateTimeBehavior=convertToNull   #kafka.eagle.username=root   #kafka.eagle.password=123456 |
| 启动Kafka Eagle                                              | 首次执行需要赋予权限   chmod +x $KE_HOME/bin/ke.sh   ke.sh start   浏览器输入：http://192.100.2.44:8048/ke   账号：admin   密码：123456 |
| 停止Kafka Eagle                                              | Ke.sh stop 或者kill 命令                                     |

 